{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Scraping using Selenium\n",
    "\n",
    "*This Notebook was originally prepared by **Jude Michael Teves**, Faculty, Department of Software Technology, College of Computer Studies, De La Salle University.*\n",
    "\n",
    "*Updated functions to use latest version of `selenium` (4.4.0) as of Sep 2022.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook, we will learn how to srape dynamic webpages using [Selenium in Python](https://selenium-python.readthedocs.io/). \n",
    "\n",
    "**Selenium** is originally a tool to automate browsers. It is still widely used for automation testing in the software development lifecycle. However, with the need for web scraping in data science projects, Selenium has become a useful tool for also automating the browser and retrieving data we need.\n",
    "\n",
    "In this example, we will be scraping the https://quotes.toscrape.com/scroll as it is dedicated for practicing scraping, similar to https://quotes.toscrape.com/. There are also other sites for practice available in the [Scraping Sanbox](https://toscrape.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder\n",
    "\n",
    "> *\"With great power, comes great responsibility\"*\n",
    "    \n",
    "Remember to perform web scraping with extra caution and to not abuse it. The boundaries are not so clear when it comes to what you can and cannot legally do with scraping. Use your own judgment to determine if what you are about to do is unethical or illegal.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "We will be using the `requests` and `BeautifulSoup` libraries for the succeeding cells. These two will give us the functionalities we need to scrape a webpage. If this is not already installed in your environment, you may use the either of the following commands in your command line:\n",
    "\n",
    "```conda install -c anaconda beautifulsoup4``` or\n",
    "```pip install beautifulsoup4```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <title>\n",
      "   Quotes to Scrape\n",
      "  </title>\n",
      "  <link href=\"/static/bootstrap.min.css\" rel=\"stylesheet\"/>\n",
      "  <link href=\"/static/main.css\" rel=\"stylesheet\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\">\n",
      "   <div class=\"row header-box\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <h1>\n",
      "      <a href=\"/\" style=\"text-decoration: none\">\n",
      "       Quotes to Scrape\n",
      "      </a>\n",
      "     </h1>\n",
      "    </div>\n",
      "    <div class=\"col-md-4\">\n",
      "     <p>\n",
      "      <a href=\"/login\">\n",
      "       Login\n",
      "      </a>\n",
      "     </p>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div class=\"row\">\n",
      "    <div class=\"col-md-8\">\n",
      "     <div class=\"quotes\">\n",
      "     </div>\n",
      "    </div>\n",
      "   </div>\n",
      "   <div id=\"loading\" style=\"background-color: #eeeecc\">\n",
      "    <h5>\n",
      "     Loading...\n",
      "    </h5>\n",
      "   </div>\n",
      "   <script src=\"/static/jquery.js\">\n",
      "   </script>\n",
      "   <script>\n",
      "    $(function(){\n",
      "        var page = 1, tag = null, hasNextPage = true;\n",
      "        function appendQuotes(quotes) {\n",
      "            var $quotes = $('.quotes');\n",
      "            var html = $.map(quotes, function(d){\n",
      "                var tags = $.map(d['tags'], function(t) {\n",
      "                    return \"<a class='tag'>\" + t + \"</a>\";\n",
      "                }).join(\" \");\n",
      "                return \"<div class='quote'><span class='text'>\" + d['text'] + \"</span><span>by <small class='author'>\" + d['author']['name'] + \"</small></span><div class='tags'>Tags: \" + tags + \"</div></div>\";\n",
      "            });\n",
      "\n",
      "            $quotes.append(html);\n",
      "        }\n",
      "\n",
      "        function updatePage(page) {\n",
      "            $('#loading').show('fast');\n",
      "            $.get('/api/quotes', {page: page}).done(function(data) {\n",
      "                appendQuotes(data.quotes);\n",
      "                hasNextPage = data.has_next;\n",
      "                $('#loading').hide('fast');\n",
      "            });\n",
      "        }\n",
      "        updatePage(page);\n",
      "        $(window).on('scroll', function(){\n",
      "            var scrollTop = $(window).scrollTop();\n",
      "            var heightDiff = $(document).height() - $(window).height();\n",
      "            if (hasNextPage && Math.abs(scrollTop - heightDiff) <= 1){\n",
      "                page += 1;\n",
      "                console.log('scrolling to page: ' + page);\n",
      "                updatePage(page);\n",
      "            }\n",
      "        });\n",
      "    });\n",
      "   </script>\n",
      "  </div>\n",
      "  <footer class=\"footer\">\n",
      "   <div class=\"container\">\n",
      "    <p class=\"text-muted\">\n",
      "     Quotes by:\n",
      "     <a href=\"https://www.goodreads.com/quotes\">\n",
      "      GoodReads.com\n",
      "     </a>\n",
      "    </p>\n",
      "    <p class=\"copyright\">\n",
      "     Made with\n",
      "     <span class=\"sh-red\">\n",
      "      ❤\n",
      "     </span>\n",
      "     by\n",
      "     <a href=\"https://scrapinghub.com\">\n",
      "      Scrapinghub\n",
      "     </a>\n",
      "    </p>\n",
      "   </div>\n",
      "  </footer>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"https://quotes.toscrape.com/scroll\")\n",
    "\n",
    "#feed it into beautiful soup for parsing\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect HTML code\n",
    "\n",
    "Inspect the code we retrieved and compare it against the webpage. This is what we should be seeing.\n",
    "\n",
    "<img src=\"./images/quotes-to-scrape-console.png\">\n",
    "\n",
    "Why is it different? Why did we not get the contents in the actual webpage? This is because the contents are dynamically generated. BeautifulSoup cannot handle such pages. And there are lots of webpages that are like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selenium to the rescue!\n",
    "\n",
    "Selenium is an automation library that can be used to deal with dynamic webpages. To install it, you may use the following commands:\n",
    "\n",
    "```conda install -c conda-forge selenium``` or\n",
    "```pip install selenium```\n",
    "\n",
    "You will also be needing a driver for your browser. See this section of the Selenium documentation for more details: https://selenium-python.readthedocs.io/installation.html#drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup browser automation\n",
    "\n",
    "You should see a new browser open after executing the cell below. This is the browser that is under the influence of our code--we are fully controlling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'webdriver_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/hxwwong/Desktop/data102/02_Lab_Selenium/02_Lab_Selenium.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hxwwong/Desktop/data102/02_Lab_Selenium/02_Lab_Selenium.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebdriver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcommon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeys\u001b[39;00m \u001b[39mimport\u001b[39;00m Keys\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hxwwong/Desktop/data102/02_Lab_Selenium/02_Lab_Selenium.ipynb#ch0000009?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebdriver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchrome\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m Service\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hxwwong/Desktop/data102/02_Lab_Selenium/02_Lab_Selenium.ipynb#ch0000009?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwebdriver_manager\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchrome\u001b[39;00m \u001b[39mimport\u001b[39;00m ChromeDriverManager\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'webdriver_manager'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to create the driver object for `selenium`. \n",
    "\n",
    "First is to use the `webdriver-manager` and install the required driver from the notebook. This will downlaod the driver on the first run if your `webdriver-manager` doesn't have the requested browser driver yet.\n",
    "\n",
    "To use this, you would also need to install the package `webdriver-manager` first before this will work.\n",
    "\n",
    "To install, run `pip3 install webdriver-manager` or `conda install -c conda-forge webdriver-manager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 1: using the webdriver-manager\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second option is when you already have your own `chromedriver.exe` downloaded, you can also use the local executable path and pass it into the `Service` object from `selenium`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option 2: using a local path \n",
    "# driver_path = os.getenv('WEBDRIVER') + '/chromedriver.exe'\n",
    "# driver = webdriver.Chrome(service=Service(driver_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise!\n",
    "\n",
    "Notice that once the driver gets initiated, a blank browser window will open in your machine. Make sure that you do not close that browser window or else, your web scraping script will not be able to find the browser anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://quotes.toscrape.com/scroll\"\n",
    "driver.get(url)\n",
    "print(driver.page_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath: Getting the elements that we want\n",
    "\n",
    "> XPath is the language used for locating nodes in an XML document. As HTML can be an implementation of XML (XHTML), Selenium users can leverage this powerful language to target elements in their web applications. XPath supports the simple methods of locating by id or name attributes and extends them by opening up all sorts of new possibilities such as locating the third checkbox on the page.\n",
    "\n",
    "For the XPath syntax, you may refer to the following link: https://www.w3schools.com/xml/xpath_syntax.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = driver.find_elements(by=\"xpath\", value=\"//div[@class='quote']\")\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_text = [quote.text for quote in quotes]\n",
    "quotes_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns all the texts inside the element. How can we choose specific parts of the element then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes[0].find_element(by=\"xpath\", value=\"span[@class='text']\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one did not return all the other text after the quote. How about the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes[0].find_element(by=\"xpath\", value=\".//small[@class='author']\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = quotes[0].find_elements(by=\"xpath\", value=\".//a[@class='tag']\")\n",
    "tags = [tag.text for tag in tags]\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle scrolling\n",
    "\n",
    "You will notice that we are only getting the first 10 quotes on the page. This is because we have to scroll first so that the other quotes get generated by the page. The following line of code automates that scrolling. Code for handling infinite scrolling is taken from <a href=\"https://stackoverflow.com/questions/28928068/scroll-down-to-bottom-of-infinite-page-with-phantomjs-in-python/28928684#28928684\">the answer to this Stackoverflow question</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "pause = 0.5\n",
    "lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(pause)\n",
    "    newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if newHeight == lastHeight:\n",
    "        break\n",
    "    lastHeight = newHeight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the quotes on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = driver.find_elements(by=\"xpath\", value=\"//div[@class='quote']\")\n",
    "len(quotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now got 100 quotes instead of 10!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Scrape the page and save the results into a `pandas` Dataframe with the following format:\n",
    "\n",
    "| author | tags | quote |\n",
    "| --- | --- | --- |\n",
    "| Albert Einstein | ['change', 'deep-thoughts', 'thinking', 'world'] | “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.“ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the first 10 records of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the last 5 records of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out the `shape` of the `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the `DataFrame` into a file called `quotes.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing the browser\n",
    "\n",
    "At the end of your scraping, make sure that you close the window of the browser by calling `driver.quit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a \"Headless\" Browser\n",
    "\n",
    "In our configuration, we ran the driver (our browser) and opened an actual window. This can be very helpful during development since the browser window will stay open (unless you call `driver.quit()`) and you can inspect the elements from that window. It can also be particularly useful for you to observe what's happening on the page and if your script is working as intended. \n",
    "\n",
    "However, once you've finalized your script and happy with the results, it is generally advisable to switch to **headless** mode in production (and in `.py` scripts).\n",
    "\n",
    "To do so, simply add some options for your driver.\n",
    "\n",
    "```python\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. https://selenium-python.readthedocs.io/\n",
    "2. https://www.scrapingbee.com/blog/selenium-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## End\n",
    "This notebook was initially written by **Jude Michael Teves** | for comments, corrections, suggestions, please email: judemichaelteves@gmail.com or jude.teves@dlsu.edu.ph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
